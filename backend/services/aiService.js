import { GoogleGenerativeAI } from '@google/generative-ai';
import mysql from 'mysql2/promise';
import logger from '../config/logger.js';
import sentimentAnalysis from './sentimentAnalysis.js';
import AiConversation from '../models/AiConversation.js';
import dotenv from 'dotenv';
import path from 'path';
import { fileURLToPath } from 'url';

// Ensure environment variables are loaded
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
try {
    dotenv.config({ path: path.join(__dirname, '../config.env') });
} catch (err) {
    dotenv.config();
}

class AIService {
    constructor() {
        this.gemini = null;
        this.dbPool = null;
        this.cache = new Map();
        this.contextMemory = new Map(); // Short-term memory
        this.initialized = false;
        this.conversationSessions = new Map(); // Track active sessions
        // Don't initialize immediately, do it lazily
    }

    /**
     * Initialize AI services and database connection
     */
    async initializeServices() {
        try {
            if (this.initialized) {
                return; // Already initialized
            }

            logger.info('ğŸ”§ Initializing Gemini AI service...');

            // Initialize Gemini - Required for AI functionality
            if (process.env.GEMINI_API_KEY && process.env.GEMINI_API_KEY !== 'your_gemini_api_key_here') {
                this.gemini = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
                logger.info('âœ… Gemini AI service initialized successfully');
            } else {
                logger.error('âŒ Gemini API key not provided - AI functionality will not work');
                logger.error('Environment variables status:');
                logger.error('- GEMINI_API_KEY exists:', !!process.env.GEMINI_API_KEY);
                logger.error('- GEMINI_API_KEY length:', process.env.GEMINI_API_KEY?.length || 0);
                throw new Error('Gemini API key is required for AI functionality');
            }

            // Initialize database connection for context
            this.dbPool = mysql.createPool({
                host: process.env.DB_HOST,
                port: process.env.DB_PORT,
                user: process.env.DB_USER,
                password: process.env.DB_PASSWORD,
                database: process.env.DB_NAME,
                waitForConnections: true,
                connectionLimit: 10,
                queueLimit: 0
            });

            this.initialized = true;
            logger.info('ğŸš€ Gemini AI Service fully initialized');
        } catch (error) {
            logger.error('âŒ Failed to initialize Gemini AI Service:', {
                message: error.message,
                stack: error.stack,
                name: error.name,
                error: error.toString()
            });
            this.initialized = false;
            throw error;
        }
    }

    /**
     * Get AI response using the configured provider
     */
    async getAIResponse(message, userId, context = {}) {
        const startTime = Date.now();

        try {
            // Initialize services if not already done
            if (!this.initialized) {
                await this.initializeServices();
            }

            // Generate session ID for conversation tracking
            const sessionId = context.sessionId || this.generateSessionId(userId);
            const conversationId = context.conversationId || this.generateConversationId(sessionId);

            // Analyze message sentiment and intent
            const messageAnalysis = await sentimentAnalysis.analyzeMessage(message);

            // Get conversation context and memory
            const conversationContext = await this.getConversationContext(userId, sessionId);

            const cacheKey = await this.generateCacheKey(message, userId, conversationContext);

            // Check cache first
            if (process.env.AI_CACHE_ENABLED === 'true' && this.cache.has(cacheKey)) {
                const cachedResponse = this.cache.get(cacheKey);
                if (this.isCacheValid(cachedResponse)) {
                    logger.info('ğŸ“¦ Returning cached AI response');

                    // Save user message to database
                    await this.saveConversation(userId, sessionId, conversationId, 'user', message, {
                        cached: true,
                        sentiment: messageAnalysis.sentiment.sentiment,
                        intent: messageAnalysis.intent.intent,
                        confidence_score: messageAnalysis.intent.confidence,
                        analysis: messageAnalysis
                    });

                    return {
                        response: cachedResponse.data,
                        cached: true,
                        timestamp: new Date(),
                        sessionId,
                        conversationId,
                        analysis: messageAnalysis
                    };
                }
            }

            // Get business context from database
            const businessContext = await this.getBusinessContext(userId);

            // Save user message to database first
            await this.saveConversation(userId, sessionId, conversationId, 'user', message, {
                sentiment: messageAnalysis.sentiment.sentiment,
                intent: messageAnalysis.intent.intent,
                confidence_score: messageAnalysis.intent.confidence,
                analysis: messageAnalysis
            });

            // Prepare enhanced message with conversation context
            const enhancedMessage = await this.prepareEnhancedMessageWithContext(
                message,
                businessContext,
                conversationContext,
                messageAnalysis,
                context
            );

            // Check if Gemini AI service is initialized
            if (!this.gemini) {
                throw new Error('Gemini AI service not initialized. Check API key.');
            }

            logger.info('ğŸ¤– Using Gemini AI with enhanced context');
            const responseStartTime = Date.now();
            const response = await this.getGeminiResponse(enhancedMessage);
            const responseTime = Date.now() - responseStartTime;

            // Update context with AI response
            await this.updateContextWithResponse(userId, sessionId, conversationId, response, {
                responseTime,
                tokensUsed: this.estimateTokens(message + response),
                cached: false
            });

            // Cache the response
            if (process.env.AI_CACHE_ENABLED === 'true') {
                this.cacheResponse(cacheKey, response);
            }

            logger.info('ğŸ¤– Enhanced AI response generated successfully', {
                responseTime: `${responseTime}ms`,
                sentiment: messageAnalysis.sentiment.sentiment,
                intent: messageAnalysis.intent.intent,
                sessionId
            });

            return {
                response,
                cached: false,
                provider: 'gemini',
                timestamp: new Date(),
                sessionId,
                conversationId,
                analysis: messageAnalysis,
                responseTime,
                metadata: {
                    tokensUsed: this.estimateTokens(message + response),
                    model: 'gemini-1.5-flash'
                }
            };

        } catch (error) {
            logger.error('âŒ Error getting AI response:', {
                message: error.message,
                stack: error.stack,
                name: error.name,
                error: error.toString()
            });
            return {
                response: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
                error: true,
                errorMessage: error.message,
                timestamp: new Date()
            };
        }
    }

    /**
     * Get response from Google Gemini
     */
    async getGeminiResponse(message) {
        try {
            if (!this.gemini) {
                throw new Error('Gemini AI service not initialized');
            }

            const model = this.gemini.getGenerativeModel({
                model: process.env.GEMINI_MODEL || 'gemini-1.5-flash'
            });

            const generationConfig = {
                temperature: parseFloat(process.env.GEMINI_TEMPERATURE || '0.4'),
                topK: parseInt(process.env.GEMINI_TOP_K || '40'),
                topP: parseFloat(process.env.GEMINI_TOP_P || '0.95'),
                maxOutputTokens: parseInt(process.env.GEMINI_MAX_TOKENS || '2048'),
            };

            logger.info('ğŸ¤– Sending request to Gemini API...');
            const result = await model.generateContent({
                contents: [{ role: 'user', parts: [{ text: message }] }],
                generationConfig
            });

            const responseText = result.response.text();
            logger.info('âœ… Gemini API response received successfully');
            return responseText;
        } catch (error) {
            logger.error('âŒ Gemini API error:', {
                message: error.message,
                status: error.status,
                statusText: error.statusText,
                stack: error.stack,
                error: error.toString()
            });
            throw new Error(`Gemini API Error: ${error.message}`);
        }
    }



    /**
     * Get business context from database
     */
    async getBusinessContext(userId) {
        try {
            const [rows] = await this.dbPool.execute(`
                SELECT 
                    (SELECT COUNT(*) FROM orders WHERE DATE(created_at) = CURDATE()) as today_orders,
                    (SELECT COUNT(*) FROM products WHERE status = 'active') as active_products,
                    (SELECT COUNT(*) FROM stores WHERE status = 'active') as active_stores,
                    (SELECT COUNT(*) FROM users WHERE status = 'active') as active_users,
                    (SELECT COALESCE(SUM(total_amount_eur), 0) FROM orders WHERE DATE(created_at) = CURDATE()) as today_revenue,
                    (SELECT COUNT(*) FROM orders WHERE status = 'pending') as pending_orders
            `);

            return rows[0] || {};
        } catch (error) {
            logger.error('âŒ Error fetching business context:', {
                message: error.message,
                stack: error.stack,
                name: error.name,
                error: error.toString()
            });
            return {};
        }
    }

    /**
     * Prepare message with business context (legacy method)
     */
    async prepareMessageWithContext(message, businessContext, additionalContext) {
        const systemPrompt = `
Ø£Ù†Øª ${process.env.BOT_NAME || 'Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø®Ø¨Ø² Ø§Ù„Ø°ÙƒÙŠ'}, Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø¨Ø².

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
- Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙŠÙˆÙ…: ${businessContext.today_orders || 0}
- Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: ${businessContext.active_products || 0}
- Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ù†Ø´Ø·Ø©: ${businessContext.active_stores || 0}
- Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù†Ø´Ø·ÙŠÙ†: ${businessContext.active_users || 0}
- Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…: ${businessContext.today_revenue || 0} ${process.env.DEFAULT_CURRENCY || 'EUR'}
- Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©: ${businessContext.pending_orders || 0}

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:
1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯
2. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø©
3. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ
4. Ø§Ø¬Ø¹Ù„ Ø±Ø¯ÙˆØ¯Ùƒ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù†Ø¸Ù…Ø©
5. Ø£Ø¶Ù Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ Ø£ÙƒØ«Ø± ÙˆØ¯ÙŠØ©

Ø§Ù„Ø³Ø¤Ø§Ù„: ${message}
`;

        return systemPrompt;
    }

    /**
     * Enhanced message preparation with conversation context and sentiment analysis
     */
    async prepareEnhancedMessageWithContext(message, businessContext, conversationContext, messageAnalysis, additionalContext) {
        // Build conversation history context
        let conversationHistory = '';
        if (conversationContext.recentConversations && conversationContext.recentConversations.length > 0) {
            conversationHistory = '\n\nØ³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©:\n';
            conversationContext.recentConversations.forEach((conv, index) => {
                const speaker = conv.message_type === 'user' ? 'Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…' : 'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯';
                conversationHistory += `${index + 1}. ${speaker}: ${conv.content.substring(0, 100)}${conv.content.length > 100 ? '...' : ''}\n`;
            });
        }

        // Build user pattern analysis
        const userStats = conversationContext.userStats || {};
        let userPatterns = '';
        if (userStats.totalMessages > 0) {
            userPatterns = `\n\nØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„: ${userStats.totalMessages}
- Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: ${Math.round(userStats.avgResponseTime || 0)}ms
- Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØªÙˆØ³Ø·: ${(userStats.avgRating || 0).toFixed(1)}/5
- Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©: ${userStats.positiveCount || 0}
- Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø³Ù„Ø¨ÙŠØ©: ${userStats.negativeCount || 0}
- Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø­Ø§ÙŠØ¯Ø©: ${userStats.neutralCount || 0}`;
        }

        // Current message analysis
        const currentAnalysis = `
ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
- Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: ${this.translateSentiment(messageAnalysis.sentiment.sentiment)} (Ø«Ù‚Ø©: ${(messageAnalysis.sentiment.confidence * 100).toFixed(1)}%)
- Ø§Ù„Ù†ÙŠØ©: ${this.translateIntent(messageAnalysis.intent.intent)} (Ø«Ù‚Ø©: ${(messageAnalysis.intent.confidence * 100).toFixed(1)}%)
- Ø§Ù„ÙØ¦Ø©: ${this.translateCategory(messageAnalysis.intent.category)}
- Ø·ÙˆÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: ${messageAnalysis.messageLength} Ø­Ø±Ù
- Ø§Ù„Ù„ØºØ©: ${messageAnalysis.language}`;

        const enhancedSystemPrompt = `
Ø£Ù†Øª ${process.env.BOT_NAME || 'Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø®Ø¨Ø² Ø§Ù„Ø°ÙƒÙŠ'}, Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªÙ‚Ø¯Ù… Ù„Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø¨Ø².

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
- Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙŠÙˆÙ…: ${businessContext.today_orders || 0}
- Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: ${businessContext.active_products || 0}
- Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ù†Ø´Ø·Ø©: ${businessContext.active_stores || 0}
- Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù†Ø´Ø·ÙŠÙ†: ${businessContext.active_users || 0}
- Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…: ${businessContext.today_revenue || 0} ${process.env.DEFAULT_CURRENCY || 'EUR'}
- Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©: ${businessContext.pending_orders || 0}

${currentAnalysis}

${conversationHistory}

${userPatterns}

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©:
1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯
2. Ø±Ø§Ø¹ÙŠ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ†ÙŠØªÙ‡ ÙÙŠ Ø§Ù„Ø±Ø¯
3. Ø§Ø³ØªÙØ¯ Ù…Ù† Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø±Ø¯ÙˆØ¯ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
4. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø®ØµØµØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
5. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ
6. Ø§Ø¬Ø¹Ù„ Ø±Ø¯ÙˆØ¯Ùƒ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù†Ø¸Ù…Ø© ÙˆÙ…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø³ÙŠØ§Ù‚
7. Ø£Ø¶Ù Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ÙƒØªØ´ÙØ©
8. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø³Ù„Ø¨ÙŠØ©ØŒ ÙƒÙ† Ø£ÙƒØ«Ø± ØªÙÙ‡Ù…Ø§Ù‹ ÙˆÙ…Ø³Ø§Ø¹Ø¯Ø©
9. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©ØŒ Ø´Ø§Ø±Ùƒ Ø§Ù„ÙØ±Ø­Ø© ÙˆÙ‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
10. Ø§Ù‚ØªØ±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø£Ùˆ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ØªØ§Ù„ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù†ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ: ${message}
`;

        return enhancedSystemPrompt;
    }

    /**
     * Translate sentiment to Arabic
     */
    translateSentiment(sentiment) {
        const translations = {
            'positive': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©',
            'negative': 'Ø³Ù„Ø¨ÙŠØ©',
            'neutral': 'Ù…Ø­Ø§ÙŠØ¯Ø©'
        };
        return translations[sentiment] || 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
    }

    /**
     * Translate intent to Arabic
     */
    translateIntent(intent) {
        const translations = {
            'question': 'Ø³Ø¤Ø§Ù„',
            'request': 'Ø·Ù„Ø¨',
            'complaint': 'Ø´ÙƒÙˆÙ‰',
            'compliment': 'Ù…Ø¬Ø§Ù…Ù„Ø©',
            'report_request': 'Ø·Ù„Ø¨ ØªÙ‚Ø±ÙŠØ±',
            'sales_inquiry': 'Ø§Ø³ØªÙØ³Ø§Ø± Ù…Ø¨ÙŠØ¹Ø§Øª',
            'inventory_inquiry': 'Ø§Ø³ØªÙØ³Ø§Ø± Ù…Ø®Ø²ÙˆÙ†',
            'store_inquiry': 'Ø§Ø³ØªÙØ³Ø§Ø± Ù…ØªØ¬Ø±',
            'greeting': 'ØªØ­ÙŠØ©',
            'goodbye': 'ÙˆØ¯Ø§Ø¹',
            'unknown': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
        };
        return translations[intent] || 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
    }

    /**
     * Translate category to Arabic
     */
    translateCategory(category) {
        const translations = {
            'business': 'Ø£Ø¹Ù…Ø§Ù„',
            'support': 'Ø¯Ø¹Ù…',
            'social': 'Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ',
            'general': 'Ø¹Ø§Ù…'
        };
        return translations[category] || 'Ø¹Ø§Ù…';
    }

    /**
     * Estimate token count (rough approximation)
     */
    estimateTokens(text) {
        if (!text) return 0;
        // Rough estimation: Arabic words are typically 1.5 tokens each
        const words = text.split(/\s+/).length;
        return Math.ceil(words * 1.5);
    }

    /**
     * Generate cache key for message
     */
    async generateCacheKey(message, userId) {
        const crypto = await import('crypto');
        return crypto.default.createHash('md5').update(`${message}_${userId}`).digest('hex');
    }

    /**
     * Cache AI response
     */
    cacheResponse(key, response) {
        const ttl = parseInt(process.env.AI_CACHE_TTL || '3600') * 1000; // Convert to milliseconds
        this.cache.set(key, {
            data: response,
            timestamp: Date.now(),
            ttl
        });

        // Clean old cache entries
        this.cleanCache();
    }

    /**
     * Check if cached response is still valid
     */
    isCacheValid(cachedItem) {
        return (Date.now() - cachedItem.timestamp) < cachedItem.ttl;
    }

    /**
     * Clean expired cache entries
     */
    cleanCache() {
        const now = Date.now();
        for (const [key, value] of this.cache.entries()) {
            if ((now - value.timestamp) >= value.ttl) {
                this.cache.delete(key);
            }
        }
    }

    /**
     * Get suggested questions based on user role and context
     */
    getSuggestedQuestions(userRole = 'user') {
        const questions = {
            admin: [
                "ğŸ“Š ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙŠÙˆÙ…ØŸ",
                "ğŸ’° Ù…Ø§ Ù‡ÙŠ Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±ØŸ",
                "ğŸª ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ù†Ø´Ø·Ø©ØŸ",
                "ğŸ“¦ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø¨ÙŠØ¹Ø§Ù‹ØŸ",
                "ğŸšš ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ…",
                "ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…"
            ],
            manager: [
                "ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…",
                "ğŸ“¦ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ø­Ø§Ù„ÙŠØ©",
                "ğŸª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø¬Ø± Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹",
                "ğŸšš ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙˆØ²ÙŠØ¹",
                "ğŸ’° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­"
            ],
            user: [
                "ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©",
                "ğŸ“¦ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
                "ğŸª Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø¬Ø±",
                "ğŸšš Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØ²ÙŠØ¹"
            ]
        };

        return questions[userRole] || questions.user;
    }

    /**
     * Clear cache
     */
    clearCache() {
        this.cache.clear();
        logger.info('ğŸ§¹ AI cache cleared');
        return { success: true, message: 'ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø¨Ù†Ø¬Ø§Ø­' };
    }

    /**
     * Get cache statistics
     */
    getCacheStats() {
        return {
            size: this.cache.size,
            maxSize: parseInt(process.env.AI_CACHE_MAX_SIZE || '1000'),
            enabled: process.env.AI_CACHE_ENABLED === 'true'
        };
    }

    /**
     * Generate session ID for conversation tracking
     */
    generateSessionId(userId) {
        return `sess_${userId}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    }

    /**
     * Generate conversation ID
     */
    generateConversationId(sessionId) {
        return `conv_${sessionId}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    }

    /**
     * Get conversation context and memory
     */
    async getConversationContext(userId, sessionId) {
        try {
            // Get short-term memory (current session)
            const shortTermKey = `${userId}_${sessionId}`;
            const shortTermMemory = this.contextMemory.get(shortTermKey) || {};

            // Get recent conversations from database (last 10 messages)
            const recentConversations = await AiConversation.findAll({
                where: { userId, sessionId },
                order: [['created_at', 'DESC']],
                limit: 10,
                attributes: ['content', 'message_type', 'sentiment', 'intent', 'created_at']
            });

            // Get user preferences and long-term patterns
            const userStats = await AiConversation.getUserStats(userId, '30d');

            return {
                shortTerm: shortTermMemory,
                recentConversations: recentConversations.reverse(), // Chronological order
                userStats,
                sessionId,
                timestamp: new Date().toISOString()
            };

        } catch (error) {
            logger.error('Error getting conversation context:', error);
            return {
                shortTerm: {},
                recentConversations: [],
                userStats: {},
                sessionId,
                timestamp: new Date().toISOString()
            };
        }
    }

    /**
     * Save conversation to database
     */
    async saveConversation(userId, sessionId, conversationId, messageType, content, metadata = {}) {
        try {
            const conversation = await AiConversation.create({
                userId,
                sessionId,
                conversationId,
                messageType,
                content,
                sentiment: metadata.sentiment || null,
                intent: metadata.intent || null,
                confidenceScore: metadata.confidence_score || null,
                responseTimeMs: metadata.response_time || null,
                tokensUsed: metadata.tokens_used || null,
                modelUsed: metadata.model_used || 'gemini-1.5-flash',
                cached: metadata.cached || false,
                metadata: {
                    ...metadata,
                    timestamp: new Date().toISOString()
                }
            });

            // Update short-term memory
            const shortTermKey = `${userId}_${sessionId}`;
            const currentMemory = this.contextMemory.get(shortTermKey) || {};

            this.contextMemory.set(shortTermKey, {
                ...currentMemory,
                lastMessage: content,
                lastMessageType: messageType,
                messageCount: (currentMemory.messageCount || 0) + 1,
                lastActivity: new Date().toISOString(),
                sentiment: metadata.sentiment,
                intent: metadata.intent
            });

            return conversation;

        } catch (error) {
            logger.error('Error saving conversation:', error);
            return null;
        }
    }

    /**
     * Enhanced cache key generation with context
     */
    async generateCacheKey(message, userId, context = {}) {
        const contextHash = JSON.stringify({
            recentMessages: context.recentConversations?.slice(-3) || [], // Last 3 messages
            userRole: context.userRole || 'user',
            sessionInfo: {
                messageCount: context.shortTerm?.messageCount || 0,
                lastIntent: context.shortTerm?.intent
            }
        });

        const crypto = await import('crypto');
        const hash = crypto.default.createHash('md5').update(message + userId + contextHash).digest('hex');
        return `ai_cache_${hash}`;
    }

    /**
     * Update conversation context with AI response
     */
    async updateContextWithResponse(userId, sessionId, conversationId, response, metadata = {}) {
        try {
            // Save AI response to database
            await this.saveConversation(userId, sessionId, conversationId, 'ai', response, {
                ...metadata,
                response_time: metadata.responseTime,
                tokens_used: metadata.tokensUsed,
                model_used: 'gemini-1.5-flash'
            });

            // Update context memory with response patterns
            const shortTermKey = `${userId}_${sessionId}`;
            const currentMemory = this.contextMemory.get(shortTermKey) || {};

            this.contextMemory.set(shortTermKey, {
                ...currentMemory,
                lastResponse: response.substring(0, 200), // Store first 200 chars
                responseCount: (currentMemory.responseCount || 0) + 1,
                lastResponseTime: metadata.responseTime,
                avgResponseTime: this.calculateAverageResponseTime(currentMemory, metadata.responseTime)
            });

        } catch (error) {
            logger.error('Error updating context with response:', error);
        }
    }

    /**
     * Calculate average response time
     */
    calculateAverageResponseTime(currentMemory, newResponseTime) {
        const currentAvg = currentMemory.avgResponseTime || 0;
        const count = currentMemory.responseCount || 0;

        if (count === 0) return newResponseTime;

        return ((currentAvg * count) + newResponseTime) / (count + 1);
    }

    /**
     * Clean expired context memory
     */
    cleanContextMemory() {
        const now = Date.now();
        const expiredKeys = [];
        const maxAge = 2 * 60 * 60 * 1000; // 2 hours

        for (const [key, memory] of this.contextMemory.entries()) {
            const lastActivity = new Date(memory.lastActivity || 0).getTime();
            if (now - lastActivity > maxAge) {
                expiredKeys.push(key);
            }
        }

        expiredKeys.forEach(key => this.contextMemory.delete(key));

        if (expiredKeys.length > 0) {
            logger.info(`ğŸ§¹ Cleaned ${expiredKeys.length} expired context memory entries`);
        }
    }
}

// Export singleton instance
export default new AIService(); 