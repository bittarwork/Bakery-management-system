import { GoogleGenerativeAI } from '@google/generative-ai';
import mysql from 'mysql2/promise';
import logger from '../config/logger.js';

class AIService {
    constructor() {
        this.gemini = null;
        this.dbPool = null;
        this.cache = new Map();
        this.initializeServices();
    }

    /**
     * Initialize AI services and database connection
     */
    async initializeServices() {
        try {
            logger.info('ğŸ”§ Initializing Gemini AI service...');

            // Initialize Gemini - Required for AI functionality
            if (process.env.GEMINI_API_KEY && process.env.GEMINI_API_KEY !== 'your_gemini_api_key_here') {
                this.gemini = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
                logger.info('âœ… Gemini AI service initialized successfully');
            } else {
                logger.error('âŒ Gemini API key not provided - AI functionality will not work');
                throw new Error('Gemini API key is required for AI functionality');
            }

            // Initialize database connection for context
            this.dbPool = mysql.createPool({
                host: process.env.DB_HOST,
                port: process.env.DB_PORT,
                user: process.env.DB_USER,
                password: process.env.DB_PASSWORD,
                database: process.env.DB_NAME,
                waitForConnections: true,
                connectionLimit: 10,
                queueLimit: 0
            });

            logger.info('ğŸš€ Gemini AI Service fully initialized');
        } catch (error) {
            logger.error('âŒ Failed to initialize Gemini AI Service:', error);
            throw error;
        }
    }

    /**
     * Get AI response using the configured provider
     */
    async getAIResponse(message, userId, context = {}) {
        try {
            const cacheKey = await this.generateCacheKey(message, userId);

            // Check cache first
            if (process.env.AI_CACHE_ENABLED === 'true' && this.cache.has(cacheKey)) {
                const cachedResponse = this.cache.get(cacheKey);
                if (this.isCacheValid(cachedResponse)) {
                    logger.info('ğŸ“¦ Returning cached AI response');
                    return {
                        response: cachedResponse.data,
                        cached: true,
                        timestamp: new Date()
                    };
                }
            }

            // Get business context from database
            const businessContext = await this.getBusinessContext(userId);

            // Prepare the enhanced message with context
            const enhancedMessage = await this.prepareMessageWithContext(message, businessContext, context);

            // Check if Gemini AI service is initialized
            if (!this.gemini) {
                throw new Error('Gemini AI service not initialized. Check API key.');
            }

            logger.info('ğŸ¤– Using Gemini AI');
            const response = await this.getGeminiResponse(enhancedMessage);

            // Cache the response
            if (process.env.AI_CACHE_ENABLED === 'true') {
                this.cacheResponse(cacheKey, response);
            }

            logger.info('ğŸ¤– Gemini AI response generated successfully');
            return {
                response,
                cached: false,
                provider: 'gemini',
                timestamp: new Date()
            };

        } catch (error) {
            logger.error('âŒ Error getting AI response:', {
                message: error.message,
                stack: error.stack,
                name: error.name,
                error: error
            });
            return {
                response: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
                error: true,
                errorMessage: error.message,
                timestamp: new Date()
            };
        }
    }

    /**
     * Get response from Google Gemini
     */
    async getGeminiResponse(message) {
        try {
            if (!this.gemini) {
                throw new Error('Gemini AI service not initialized');
            }

            const model = this.gemini.getGenerativeModel({
                model: process.env.GEMINI_MODEL || 'gemini-1.5-flash'
            });

            const generationConfig = {
                temperature: parseFloat(process.env.GEMINI_TEMPERATURE || '0.4'),
                topK: parseInt(process.env.GEMINI_TOP_K || '40'),
                topP: parseFloat(process.env.GEMINI_TOP_P || '0.95'),
                maxOutputTokens: parseInt(process.env.GEMINI_MAX_TOKENS || '2048'),
            };

            logger.info('ğŸ¤– Sending request to Gemini API...');
            const result = await model.generateContent({
                contents: [{ role: 'user', parts: [{ text: message }] }],
                generationConfig
            });

            const responseText = result.response.text();
            logger.info('âœ… Gemini API response received successfully');
            return responseText;
        } catch (error) {
            logger.error('âŒ Gemini API error:', {
                message: error.message,
                status: error.status,
                statusText: error.statusText,
                stack: error.stack
            });
            throw new Error(`Gemini API Error: ${error.message}`);
        }
    }



    /**
     * Get business context from database
     */
    async getBusinessContext(userId) {
        try {
            const [rows] = await this.dbPool.execute(`
                SELECT 
                    (SELECT COUNT(*) FROM orders WHERE DATE(created_at) = CURDATE()) as today_orders,
                    (SELECT COUNT(*) FROM products WHERE status = 'active') as active_products,
                    (SELECT COUNT(*) FROM stores WHERE status = 'active') as active_stores,
                    (SELECT COUNT(*) FROM users WHERE status = 'active') as active_users,
                    (SELECT SUM(total_amount) FROM orders WHERE DATE(created_at) = CURDATE()) as today_revenue,
                    (SELECT COUNT(*) FROM orders WHERE status = 'pending') as pending_orders
            `);

            return rows[0] || {};
        } catch (error) {
            logger.error('âŒ Error fetching business context:', error);
            return {};
        }
    }

    /**
     * Prepare message with business context
     */
    async prepareMessageWithContext(message, businessContext, additionalContext) {
        const systemPrompt = `
Ø£Ù†Øª ${process.env.BOT_NAME || 'Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø®Ø¨Ø² Ø§Ù„Ø°ÙƒÙŠ'}, Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø¨Ø².

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
- Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙŠÙˆÙ…: ${businessContext.today_orders || 0}
- Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: ${businessContext.active_products || 0}
- Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ù†Ø´Ø·Ø©: ${businessContext.active_stores || 0}
- Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù†Ø´Ø·ÙŠÙ†: ${businessContext.active_users || 0}
- Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…: ${businessContext.today_revenue || 0} ${process.env.DEFAULT_CURRENCY || 'EUR'}
- Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©: ${businessContext.pending_orders || 0}

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:
1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯
2. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø©
3. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ
4. Ø§Ø¬Ø¹Ù„ Ø±Ø¯ÙˆØ¯Ùƒ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù†Ø¸Ù…Ø©
5. Ø£Ø¶Ù Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ Ø£ÙƒØ«Ø± ÙˆØ¯ÙŠØ©

Ø§Ù„Ø³Ø¤Ø§Ù„: ${message}
`;

        return systemPrompt;
    }

    /**
     * Generate cache key for message
     */
    async generateCacheKey(message, userId) {
        const crypto = await import('crypto');
        return crypto.default.createHash('md5').update(`${message}_${userId}`).digest('hex');
    }

    /**
     * Cache AI response
     */
    cacheResponse(key, response) {
        const ttl = parseInt(process.env.AI_CACHE_TTL || '3600') * 1000; // Convert to milliseconds
        this.cache.set(key, {
            data: response,
            timestamp: Date.now(),
            ttl
        });

        // Clean old cache entries
        this.cleanCache();
    }

    /**
     * Check if cached response is still valid
     */
    isCacheValid(cachedItem) {
        return (Date.now() - cachedItem.timestamp) < cachedItem.ttl;
    }

    /**
     * Clean expired cache entries
     */
    cleanCache() {
        const now = Date.now();
        for (const [key, value] of this.cache.entries()) {
            if ((now - value.timestamp) >= value.ttl) {
                this.cache.delete(key);
            }
        }
    }

    /**
     * Get suggested questions based on user role and context
     */
    getSuggestedQuestions(userRole = 'user') {
        const questions = {
            admin: [
                "ğŸ“Š ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙŠÙˆÙ…ØŸ",
                "ğŸ’° Ù…Ø§ Ù‡ÙŠ Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±ØŸ",
                "ğŸª ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ù†Ø´Ø·Ø©ØŸ",
                "ğŸ“¦ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø¨ÙŠØ¹Ø§Ù‹ØŸ",
                "ğŸšš ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ…",
                "ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…"
            ],
            manager: [
                "ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…",
                "ğŸ“¦ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ø­Ø§Ù„ÙŠØ©",
                "ğŸª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø¬Ø± Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹",
                "ğŸšš ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙˆØ²ÙŠØ¹",
                "ğŸ’° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­"
            ],
            user: [
                "ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©",
                "ğŸ“¦ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
                "ğŸª Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø¬Ø±",
                "ğŸšš Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØ²ÙŠØ¹"
            ]
        };

        return questions[userRole] || questions.user;
    }

    /**
     * Clear cache
     */
    clearCache() {
        this.cache.clear();
        logger.info('ğŸ§¹ AI cache cleared');
        return { success: true, message: 'ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø¨Ù†Ø¬Ø§Ø­' };
    }

    /**
     * Get cache statistics
     */
    getCacheStats() {
        return {
            size: this.cache.size,
            maxSize: parseInt(process.env.AI_CACHE_MAX_SIZE || '1000'),
            enabled: process.env.AI_CACHE_ENABLED === 'true'
        };
    }
}

// Export singleton instance
export default new AIService(); 